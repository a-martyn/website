
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="../css/notebook.css" type="text/css" />
</head>
<body>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="How-residual-shortcuts-speed-up-learning:-a-minimal-demonstration">How residual shortcuts speed up learning: a minimal demonstration<a class="anchor-link" href="#How-residual-shortcuts-speed-up-learning:-a-minimal-demonstration">&#182;</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The original <a href="https://arxiv.org/abs/1512.03385">ResNet</a> paper by Kaiming He et al. demonstrates the effect of residual shortcuts in large convolutional neural networks with up to 110 layers and 1.7 million parameters. In this notebook we'll explore the residual shortcut in the extreme minimal setting with just one layer and only 9 parameters. Although not quite as cool as winning ImageNet, as ResNet did in 2016, I hope this approach helps to clarify residual shortcuts, what they're good for, and how to use them.</p>
<p>The ResNet architecture enables 110-layer convolutional networks to outperform 20-layer networks and in 2016 achieved state-of-the-art in computer vision classification tasks. The core idea is simple, a stack of 2-3 convolutional layers circumvented by a 'shortcut' connection from input to output. These 'residual blocks' are themselves stacked together to form the ResNet model, and appear often in machine learning literature, Kaggle entries and beyond.</p>
<p><img src="./assets/resnet_block.jpg" alt="Resnet Block"></p>
<ul>
<li>Figure 1. A ResNet block and the ResNet architecture</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Prelims">Prelims<a class="anchor-link" href="#Prelims">&#182;</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[1]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Motivation">Motivation<a class="anchor-link" href="#Motivation">&#182;</a></h2><p>He et al. start from the observation that state-of-the-art 20-layer convolutional models out performed 56-layer models on image classification tasks at that time (Fig. 2).</p>
<p><img src="./assets/fig1.png" alt="Fig. 2"></p>
<ul>
<li>Figure 2. "Training error (left) and test error (right) on CIFAR-10 with 20-layer and 56-layer “plain” networks. The deeper network has higher training error, and thus test error. Similar phenomena on ImageNet is presented in Fig. 4." (from original paper)</li>
</ul>
<p>This might be surprising. Why doesn't the 56-layer model perform at least as well as the 20-layer model? We might expect that the first 20-layers of the 56-layer model could learn identical weights to the 20-layer model, then the remaining layers just need to output their input. In linear algebra the function that outputs its input is the identity function.</p>
<p>He et al. hypothesised that latter layers in the 56-layer model have a detrimental effect on performance because convolutional layers struggle to learn the identity function. So how might we make it easier for convolutional layers to learn the identity function? Or put another way, how might we make it easier for convolutional layers to output their input?</p>
<p>The ResNet approach is simple, provide a shortcut connection from the input of a layer to its output where the input is added element-wise to the output matrix. The example illustrated in Fig 1. provides a shortcut across two layers. Without a shortcut connection these layers must learn a function that maps the input to the desired output directly.</p>
$$z = f(x) $$<p></p>
<ul>
<li>Equation 1.</li>
</ul>
<p>Where $x$ is the input, $f(x)$ is some function that the layers learn, and $z$ is the output returned by that function.</p>
<p>With a shortcut connection the layers learn the difference, or <strong>the residual</strong>, between input and output.</p>
$$z = x + f(x) $$<p></p>
<ul>
<li>Equation 2.</li>
</ul>
<p>A simple change but this now means that if the optimal solution is to model the identity function then the layer learns to output a zero matrix for all inputs e.g. $f(x) = 0$. The assumption being that it is easier for a convolutional layer to learn $f(x)$ that returns zero, than it is to learn $f(x)$ that returns $x$. In the authors' words:</p>
<blockquote><p>"We hypothesize that it is easier to optimize the residual mapping than to optimize the original, unreferenced mapping. To the extreme, if an identity mapping were optimal, it would be easier to push the residual to zero than to fit an identity mapping by a stack of nonlinear layers." - He et al. 2015</p>
</blockquote>
<p>Whilst working on my own <a href="https://github.com/a-martyn/resnet">implementation of the ResNet paper</a>, I found this assumption surprising. Why would it be any easier for a convolutional layer to learn a function that maps to zero than it is to learn the identity function? Let's take a closer look.</p>
<h2 id="A-minimal-example">A minimal example<a class="anchor-link" href="#A-minimal-example">&#182;</a></h2><p>Let's consider a minimal example, a single convolutional layer that outputs an array of the same shape as its input with kernel size 3, stride 1, padding 1. Our input is a tiny 3x3 grayscale image with a single channel. Let's assume that the objective is to perform the identity mapping.</p>
<p>With a residual shortcut in place the layer's objective is to output a matrix of zeros irrespective of input because input is added to the layers output output via the shortcut (see equation 2.).</p>
<p><img src="./assets/ZeroConv.jpg" alt="Figure 3."></p>
<ul>
<li>Figure 3. Optimal parameters for a 3x3, stride 1 convolution that maps any input to zero.</li>
</ul>
<p>To achieve this we would like kernel weights that return an output of zero regardless of input as the kernel is convolved left-to-right, top-to-bottom across the input. In Figure 3. imagine the blue outline at every possible position. If every weight in the kernel is zero, then every input will be multiplied by zero and so the output must be zero in every position. So the optimal kernel will be an array of zeros. Here's the equivalent in code:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[13]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Manually set the weights, there&#39;s only one 3x3 kernel in this model</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[[</span><span class="mf">0.0</span><span class="p">,</span>  <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
                          <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span>  <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
                          <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span>  <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]]]],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># Generate random input x</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="c1"># Forward pass</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">weights</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Input:</span><span class="se">\n</span><span class="s1"> </span><span class="si">{x}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Output:</span><span class="se">\n</span><span class="s1"> </span><span class="si">{z}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Input:
 tensor([[[[0.7315, 0.1468, 0.2154],
          [0.2992, 0.8183, 0.1114],
          [0.6382, 0.7877, 0.4554]]]])
Output:
 tensor([[[[0., 0., 0.],
          [0., 0., 0.],
          [0., 0., 0.]]]], grad_fn=&lt;ThnnConv2DBackward&gt;)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As expected the output is zero, run the above code block multiple times to check this is the case for other inputs. Next let's consider the weights needed to perform an identity mapping In this case the only thing we change is to set the central kernel weight to <code>1.0</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="./assets/IdentityConv.jpg" alt="Figure 4."></p>
<ul>
<li>Figure 4. Optimal parameters for a 3x3, stride 1 convolution that maps any input to the unaltered input.</li>
</ul>
<p>Without a shortcut connection the layers' objective becomes to output its input (see equation 1.). Intuitively the kernel selects the central pixel at each position and ignores all others. Here's a code example:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[10]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Set weights to zero to ouput zero</span>
<span class="n">weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[[[</span><span class="mf">0.0</span><span class="p">,</span>  <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
                          <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span>  <span class="mf">1.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">],</span>
                          <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span>  <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">]]]],</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># Generate random input x</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
<span class="c1"># Forward pass</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">weights</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Input:</span><span class="se">\n</span><span class="s1"> </span><span class="si">{x}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Output:</span><span class="se">\n</span><span class="s1"> </span><span class="si">{z}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Input:
 tensor([[[[0.8361, 0.3069, 0.6524],
          [0.2145, 0.2745, 0.6489],
          [0.1664, 0.5390, 0.9452]]]])
Output:
 tensor([[[[0.8361, 0.3069, 0.6524],
          [0.2145, 0.2745, 0.6489],
          [0.1664, 0.5390, 0.9452]]]], grad_fn=&lt;ThnnConv2DBackward&gt;)
</pre>
</div>
</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>By setting the central kernel weight to <code>1.0</code>, the layer now performs an identity mapping - the output is the same as the input.</p>
<p>If He's hypothesis is correct we expect that learning the identity objective should be harder than learning the zero objective. It's still not obvious that this is the case but it turns out we can run a very minimal experiment to see for ourselves.</p>
<h2 id="Experiment">Experiment<a class="anchor-link" href="#Experiment">&#182;</a></h2><p>Following from He's hypothesis that a convolutional layer with a residual shortcut can more easily learn the identity function, it follows that a convolutional layer can learn to map any input zero faster than it can learn the identity function directly.</p>
<p>To test this we'll create the exact same minimal model illustrated in figures 3 &amp; 4, a single convolutional layer with a 3x3 kernel, stride 1, and padding 1. We add a ReLU activation function and initialise the 9 learn-able parameters with Kaiming He's normal initilisation method. Here's our minimal model:</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[11]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">OneConv</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Minimal PyTorch model with single convolutional layer&quot;&quot;&quot;</span>
    
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">channels</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Initialise the model&quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> 
                               <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
        <span class="c1"># Initialise weights </span>
        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
                <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;fan_out&#39;</span><span class="p">,</span> 
                                        <span class="n">nonlinearity</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Run a forward pass&quot;&quot;&quot;</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Next we need a training loop. We use an L1 loss function to measure the absolute difference between the target and the output of the model. With mean reduction across each pixel this is expressed as...</p>
$$l = \frac{\sum_{i=1}^{n}|x_i - y_i|}{n}$$<ul>
<li>l: (scalar) loss</li>
<li>n: (scalar) number of samples in dataset</li>
<li>x: (array) input sample</li>
<li>y: (array) target output</li>
</ul>
<p>The rest is a vanilla backpropagation training loop using an Adam optimiser.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[4]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">epochs</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Initialises a new model, then trains it for the given number of epochs. </span>
<span class="sd">    The input samples are provide as the array `X` and the targets are </span>
<span class="sd">    provided as an array of the same shape `Y`. The mean loss for each </span>
<span class="sd">    epoch is returned as a list.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Initilise model</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">OneConv</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">L1Loss</span><span class="p">()</span>

    <span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
        <span class="c1"># Train model for an epoch</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">z</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">Y</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

        <span class="c1"># Record mean loss for this epoch</span>
        <span class="n">losses</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">running_loss</span> <span class="o">/</span> <span class="n">epochs</span><span class="p">)</span>
        <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">return</span> <span class="n">losses</span>
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we can run our experiment. We run the experiment multiple times to account for variance due to randomised inputs and weights. For each experiment we generate an array of 200 input samples <code>X</code>. For the identity setting we train a model to map X to X. In the zero setting we train another instance of our model to output zero for each input.</p>
<p>We aggregate the results from each experiment and plot the mean and 95% confidence intervals. (takes ~3 minutes to run on CPU)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[5]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">n_samples</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">20</span>
<span class="n">experiments</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">epochs_idx</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">losses</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">experiment</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Run each experiment multiple times and accumulate results</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">experiments</span><span class="p">):</span>
    <span class="c1"># Input is random 3x3 matrix</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="c1"># Target is zeros</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">n_samples</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>

    <span class="c1"># Train a model to map input to output, the identity function</span>
    <span class="n">losses</span> <span class="o">+=</span> <span class="n">train</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">epochs</span><span class="p">)</span>
    <span class="n">experiment</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;identity&#39;</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">)]</span>
    <span class="n">epochs_idx</span> <span class="o">+=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">))</span>
    
    <span class="c1"># Train a model to map input to zeros</span>
    <span class="n">losses</span> <span class="o">+=</span> <span class="n">train</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">,</span> <span class="n">epochs</span><span class="p">)</span>
    <span class="n">experiment</span> <span class="o">+=</span> <span class="p">[</span><span class="s1">&#39;zero&#39;</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">)]</span>
    <span class="n">epochs_idx</span> <span class="o">+=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">))</span>
 
</pre></div>

    </div>
</div>
</div>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[6]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Plot results with mean and 95% confidence intervals</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s1">&#39;epoch&#39;</span><span class="p">:</span> <span class="n">epochs_idx</span><span class="p">,</span> 
                   <span class="s1">&#39;L1_loss&#39;</span><span class="p">:</span> <span class="n">losses</span><span class="p">,</span> 
                   <span class="s1">&#39;experiment&#39;</span><span class="p">:</span> <span class="n">experiment</span><span class="p">})</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s1">&#39;L1_loss&#39;</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s1">&#39;experiment&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;gray&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Comparison of training loss in identity and zero settings.&#39;</span><span class="p">);</span> 
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
"
>
</div>

</div>

</div>
</div>

</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In the zero setting the model reduces loss to below 0.01 (dashed line) in 3.5 epochs, in the identity setting the model takes 10 epochs to achieve this. The wider confidence interval indicates greater variance in the identity setting.</p>
<p>Even in this very minimal setting, there is evidence to support He's hypothesis. The model learns a mapping to zero almost three times faster than it learns the identity function.</p>
<h2 id="A-less-minimal-experiment">A less minimal experiment<a class="anchor-link" href="#A-less-minimal-experiment">&#182;</a></h2><p>At this point you might not be convinced that theses observations from the extreme minimal setting extrapolate to more complex settings with larger inputs and more than one layer with more parameters. To check this I ran a similar experiment but with a full 2-layer ResNet block and 512px images as input. The code for this experiment is available <a href="https://nbviewer.jupyter.org/github/a-martyn/resnet/blob/master/docs/notebooks/resnet_membrane_demo.ipynb">here</a>, and the results are below.</p>
<p><img src="./assets/membrane_results.png" alt="Membrane results"></p>
<p>The model with a residual shortcut clearly outperforms the no-shortcut model in this setting too.</p>
<h2 id="Discussion">Discussion<a class="anchor-link" href="#Discussion">&#182;</a></h2><p>Why do convolutional networks learn the zero mapping more easily than the identity mapping? If we can answer this question then we can understand <em>why</em> residual shortcuts improve performance. In the minimal setting there's only two practical differences I can think of:</p>
<ol>
<li><strong>Weight configuration:</strong> The optimal weights differ as discussed, in the zero setting all zero and in the identity setting the central weight is one and the rest zero.</li>
<li><strong>Target variance:</strong> In the identity setting the target is the input which differs at each training step. In the zero setting the target is identical at every step, it is always a zero matrix.</li>
</ol>
<p>Further investigation is needed. Intuitively, I can't see how the difference in optimal weight could be significant. My guess would be that the target variance is the cause. In the identity setting there is variance between targets at each step, and for some samples there will exist solutions that work for that specific case but that don't generalise. For example a kernel with the bottom-right value set to <code>1.0</code> performs quite well in this particular case with only one pixel in error (highlighted red).</p>
<p><img src="./assets/NonGeneralB.jpg" alt=""></p>
<ul>
<li>Figure 5. Example of suboptimal kernel weights for identity mapping.</li>
</ul>
<p>Such cases could introduce variance when calculating backpropagation gradients which seems likely to impede convergence. Conversely in the zero setting there is no variance between targets, the target is always a zero matrix.</p>
<h2 id="Summary">Summary<a class="anchor-link" href="#Summary">&#182;</a></h2><p>He et al. hypothesized that residual shortcuts help convolutional layers learn identity mappings and showed that they can improve performance of convolutional networks over.</p>
<p>When the optimal output of a layer is close to the identity function then the residual shortcut ensures that the optimal layer activations are close to zero with reduced variance. We ran a minimal experiment to show that convolutional layers converge faster to a zero mapping with no variance in target activations, than to an identity mapping with high variance.</p>
<p>Practically speaking, this suggests that if you can reduce the variance in the target activations of convolutional layers within your model then you can speed up convergence and perhaps initiate convergence in layers that otherwise would fail to do so. In other words, how can we encourage a models' activations to be more consistent across training samples?</p>
<p>Next we might ask: Do these insights apply to nonlinear layers other than convolutions? In settings with other objectives and architectures is the residual the best assumption as to what layers are modeling? If not, do other shortcuts or different techniques for reducing activation variance work better?</p>
<p>In the next post I'll discuss the U-net, another breakthrough architecture that uses the shortcut technique. If you want to explore the full ResNet architecture then please take a look at my <a href="https://github.com/a-martyn/resnet">PyTorch implementation</a>.</p>
<p>Thanks for reading. Any feedback, thoughts or corrections most welcome.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>
</body>
</html>

